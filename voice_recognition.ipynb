{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOiOqLgJOTwcjwU5pW1ycZq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kth0522/AI_news/blob/main/voice_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**라이브러리 설치**"
      ],
      "metadata": {
        "id": "u0z4x8EHYRpO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3qgEcOmYFSt",
        "outputId": "419c4c9c-dd99-4d03-b81f-6bc964af451f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai-whisper in /usr/local/lib/python3.10/dist-packages (20231117)\n",
            "Requirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.1.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.58.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (1.23.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.1.0+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (4.66.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (10.1.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.5.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper) (3.13.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (0.41.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (2023.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n",
            "Requirement already satisfied: pathlib in /usr/local/lib/python3.10/dist-packages (1.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U openai-whisper\n",
        "!pip install pydub\n",
        "!pip install pathlib"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**코드**"
      ],
      "metadata": {
        "id": "Y3xDIlu8ZHp7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "import csv\n",
        "from pydub import AudioSegment\n",
        "import os\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "8QVOqCGWY1yR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = whisper.load_model(\"medium\")\n",
        "\n",
        "def process_audio_files(input_folder, transcription_folder, segments_folder):\n",
        "    for audio_file_path in Path(input_folder).glob(\"*.wav\"):\n",
        "        file_name = audio_file_path.stem\n",
        "        output_csv_path = Path(transcription_folder) / f\"{file_name}.csv\"\n",
        "        output_segments_dir = Path(segments_folder) / file_name\n",
        "\n",
        "        output_csv_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "        output_segments_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        result = model.transcribe(str(audio_file_path))\n",
        "\n",
        "        with open(output_csv_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
        "            csvwriter = csv.writer(csvfile)\n",
        "            csvwriter.writerow(['id', 'start', 'end', 'text'])\n",
        "            for segment in result['segments']:\n",
        "                csvwriter.writerow([segment['id'], segment['start'], segment['end'], segment['text']])\n",
        "\n",
        "        audio = AudioSegment.from_wav(str(audio_file_path))\n",
        "\n",
        "        for segment in result[\"segments\"]:\n",
        "            start = int(segment[\"start\"] * 1000)\n",
        "            end = int(segment[\"end\"] * 1000)\n",
        "            cropped = audio[start:end]\n",
        "            cropped.export(output_segments_dir / f\"{segment['id']}.wav\", format=\"wav\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kh82cTYfY-V7",
        "outputId": "0bb9fd9f-2406-4030-a0a0-b66191bb2fd0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████████████████████████████| 1.42G/1.42G [00:16<00:00, 90.3MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**실행**"
      ],
      "metadata": {
        "id": "OI2m1MbJZMrc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 입력 폴더\n",
        "INPUT_DIR = './vocal_samples'\n",
        "\n",
        "# transcription 결과 저장 폴더\n",
        "TRANSCRIPTION_DIR = './transcriptions'\n",
        "\n",
        "# voice segment 결과 저장 폴더\n",
        "SEGMENTS_DIR = './segments'"
      ],
      "metadata": {
        "id": "JVysfRScZJ9A"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "process_audio_files(input_folder=INPUT_DIR, transcription_folder=TRANSCRIPTION_DIR, segments_folder=SEGMENTS_DIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kShD3-Opaao3",
        "outputId": "58479343-ac4f-4bed-d950-6b7f9ad6aca9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        }
      ]
    }
  ]
}