{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNOxWz2R3q45wG7KWDVwASn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kth0522/AI_news/blob/main/vocal_separation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**라이브러리**"
      ],
      "metadata": {
        "id": "N8nhXbrr8EXQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "xOuYXeDv7U5S"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchaudio\n",
        "import torchaudio.transforms as T\n",
        "from torchaudio.pipelines import HDEMUCS_HIGH_MUSDB_PLUS"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**디바이스 설정 및 모델 선언**"
      ],
      "metadata": {
        "id": "rUa8AgKf8TrR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "bundle = HDEMUCS_HIGH_MUSDB_PLUS\n",
        "model = bundle.get_model()\n",
        "model.to(device)\n",
        "sample_rate = bundle.sample_rate"
      ],
      "metadata": {
        "id": "VD3MjLVO8NqQ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Helper Functions**"
      ],
      "metadata": {
        "id": "CaAShToz83kO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def separate_sources(\n",
        "    model,\n",
        "    mix,\n",
        "    segment=10.,\n",
        "    overlap=0.1,\n",
        "    device=None,\n",
        "):\n",
        "    if device is None:\n",
        "        device = mix.device\n",
        "    else:\n",
        "        device = torch.device(device)\n",
        "\n",
        "    batch, channels, length = mix.shape\n",
        "\n",
        "    chunk_len = int(sample_rate * segment * (1 + overlap))\n",
        "    start = 0\n",
        "    end = chunk_len\n",
        "    overlap_frames = overlap * sample_rate\n",
        "    fade = T.Fade(fade_in_len=0, fade_out_len=int(overlap_frames), fade_shape='linear')\n",
        "\n",
        "    final = torch.zeros(batch, len(model.sources), channels, length, device=device)\n",
        "\n",
        "    while start < length - overlap_frames:\n",
        "        chunk = mix[:, :, start:end]\n",
        "        with torch.no_grad():\n",
        "            out = model.forward(chunk)\n",
        "        out = fade(out)\n",
        "        final[:, :, :, start:end] += out\n",
        "        if start == 0:\n",
        "            fade.fade_in_len = int(overlap_frames)\n",
        "            start += int(chunk_len - overlap_frames)\n",
        "        else:\n",
        "            start += chunk_len\n",
        "        end += chunk_len\n",
        "        if end >= length:\n",
        "            fade.fade_out_len = 0\n",
        "    return final\n",
        "\n",
        "def separate_and_save_sources(wav_path, output_dir):\n",
        "    waveform, sr = torchaudio.load(wav_path)\n",
        "    waveform = waveform.to(device)\n",
        "    mixture = waveform\n",
        "\n",
        "    segment = 10\n",
        "    overlap = 0.1\n",
        "\n",
        "    ref = waveform.mean(0)\n",
        "    waveform = (waveform - ref.mean()) / ref.std()\n",
        "\n",
        "    sources = separate_sources(\n",
        "        model,\n",
        "        waveform[None],\n",
        "        device=device,\n",
        "        segment=segment,\n",
        "        overlap=overlap,\n",
        "    )[0]\n",
        "    sources = sources * ref.std() + ref.mean()\n",
        "\n",
        "    sources = sources.cpu()\n",
        "\n",
        "    file_name = os.path.splitext(os.path.basename(wav_path))[0]\n",
        "\n",
        "    for i, source in enumerate(model.sources):\n",
        "        if source == \"vocals\":\n",
        "            print(file_name)\n",
        "            output_path = os.path.join(output_dir, f\"{file_name}.wav\")\n",
        "            torchaudio.save(output_path, sources[i], sample_rate)\n",
        "\n",
        "\n",
        "\n",
        "def process_all_wav_in_folder(input_folder_path, output_folder_path):\n",
        "    if not os.path.exists(output_folder_path):\n",
        "        os.makedirs(output_folder_path)\n",
        "\n",
        "    for filename in os.listdir(input_folder_path):\n",
        "        if filename.endswith(\".wav\"):\n",
        "            wav_path = os.path.join(input_folder_path, filename)\n",
        "            separate_and_save_sources(wav_path, output_folder_path)\n"
      ],
      "metadata": {
        "id": "uhc1jwGR82gy"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**실행** \\\n",
        "입력 폴더에 wav 파일들 넣고 실행"
      ],
      "metadata": {
        "id": "JGSmYLvO9odI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_DIRS = './audios'\n",
        "OUTPUT_DIRS = './outputs'"
      ],
      "metadata": {
        "id": "VZHOBESD9Ej-"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "process_all_wav_in_folder(input_folder_path=INPUT_DIRS, output_folder_path=OUTPUT_DIRS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z53af9V-90I1",
        "outputId": "b11d5e1d-8221-4d31-fa33-0c659a98debf"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mbn_ai_1\n"
          ]
        }
      ]
    }
  ]
}